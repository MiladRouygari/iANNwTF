{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # For matrix math\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "\n",
    "import sys # For printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training data.\n",
    "X = np.array([\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [0, 0]\n",
    "])\n",
    "\n",
    "# The labels for the training data.\n",
    "y = np.array([\n",
    "    [1],\n",
    "    [1],\n",
    "    [0],\n",
    "    [0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_i_units = 2 # Number of Input units\n",
    "num_h_units = 2 # Number of Hidden units\n",
    "num_o_units = 1 # Number of Output units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The learning rate for Gradient Descent.\n",
    "learning_rate = 0.01\n",
    "\n",
    "# The parameter to help with overfitting.\n",
    "reg_param = 0\n",
    "\n",
    "# Maximum iterations for Gradient Descent.\n",
    "max_iter = 5000\n",
    "\n",
    "# Number of training examples\n",
    "m = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "W1 = np.random.normal(0, 1, (num_h_units, num_i_units)) # 2x2\n",
    "W2 = np.random.normal(0, 1, (num_o_units, num_h_units)) # 1x2\n",
    "\n",
    "B1 = np.random.random((num_h_units, 1)) # 2x1\n",
    "B2 = np.random.random((num_o_units, 1)) # 1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62434536, -0.61175641],\n",
       "       [-0.52817175, -1.07296862]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.86540763, -2.3015387 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41919451],\n",
       "       [0.6852195 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20445225]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z, derv=False):\n",
    "    if derv: return z * (1 - z)\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, predict=False):\n",
    "    a1 = x.reshape(x.shape[0], 1) # Getting the training example as a column vector.\n",
    "\n",
    "    z2 = W1.dot(a1) + B1 # 2x2 * 2x1 + 2x1 = 2x1\n",
    "    a2 = sigmoid(z2) # 2x1\n",
    "\n",
    "    z3 = W2.dot(a2) + B2 # 1x2 * 2x1 + 1x1 = 1x1\n",
    "    a3 = sigmoid(z3)\n",
    "\n",
    "    if predict: return a3\n",
    "    return (a1, a2, a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients for the Weights and Biases\n",
    "These variables will contain the gradients for the weights and biases which will be used by gradient descent to update the weights and biases.\n",
    "\n",
    "Also, creating the vector which will be storing the cost values for each gradient descent iteration to help visualize the cost as the weights and biases are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW1 = 0 # Gradient for W1\n",
    "dW2 = 0 # Gradient for W2\n",
    "\n",
    "dB1 = 0 # Gradient for B1\n",
    "dB2 = 0 # Gradient for B2\n",
    "\n",
    "cost = np.zeros((max_iter, 1)) # Column vector to record the cost of the NN after each Gradient Descent iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "This is the training function which contains the meat of NN. This contains forward propagation and [Backpropagation](http://neuralnetworksanddeeplearning.com/chap2.html).\n",
    "\n",
    "### Backpropagation\n",
    "The process of propagating the error in the output layer, backwards through the NN to calculate the error in each layer. Intuition: It's like forward propagation, but backwards.\n",
    "\n",
    "Steps(for this NN):\n",
    "1. Calculate the error in the output layer(dz2).\n",
    "2. Calculate the error in the weights connecting the hidden layer to the output layer using dz2 (dW2).\n",
    "3. Calculate the error in the hidden layer(dz1).\n",
    "4. Calculate the error in the weights connecting the input layer to the hidden layer using dz1 (dW1).\n",
    "5. The errors in the biases are just the errors in the respective layers.\n",
    "\n",
    "Afterwards, the gradients(errors) of the weights and biases are used to update the corresponding weights and biases by multiplying them with the negative of the learning rate and scaling it by divinding it by the number of training examples.\n",
    "\n",
    "While iterating over all the training examples, the cost is also being calculated simultaneously for each example. Then, a regurlization parameter is added, although for such a small dataset, regularization is unnecessary since to perform well, the NN will have to over fit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(_W1, _W2, _B1, _B2): # The arguments are to bypass UnboundLocalError error\n",
    "    for i in range(max_iter):\n",
    "        c = 0\n",
    "        \n",
    "        dW1 = 0\n",
    "        dW2 = 0\n",
    "\n",
    "        dB1 = 0\n",
    "        dB2 = 0\n",
    "        \n",
    "        for j in range(m):\n",
    "            sys.stdout.write(\"\\rIteration: {} and {}\".format(i + 1, j + 1))\n",
    "\n",
    "            # Forward Prop.\n",
    "            a0 = X[j].reshape(X[j].shape[0], 1) # 2x1\n",
    "\n",
    "            z1 = _W1.dot(a0) + _B1 # 2x2 * 2x1 + 2x1 = 2x1\n",
    "            a1 = sigmoid(z1) # 2x1\n",
    "\n",
    "            z2 = _W2.dot(a1) + _B2 # 1x2 * 2x1 + 1x1 = 1x1\n",
    "            a2 = sigmoid(z2) # 1x1\n",
    "\n",
    "            # Back prop.\n",
    "            dz2 = a2 - y[j] # 1x1\n",
    "            dW2 += dz2 * a1.T # 1x1 .* 1x2 = 1x2\n",
    "\n",
    "            dz1 = np.multiply((_W2.T * dz2), sigmoid(a1, derv=True)) # (2x1 * 1x1) .* 2x1 = 2x1\n",
    "            dW1 += dz1.dot(a0.T) # 2x1 * 1x2 = 2x2\n",
    "\n",
    "            dB1 += dz1 # 2x1\n",
    "            dB2 += dz2 # 1x1\n",
    "\n",
    "            c = c + (-(y[j] * np.log(a2)) - ((1 - y[j]) * np.log(1 - a2)))\n",
    "            sys.stdout.flush() # Updating the text.\n",
    "        \n",
    "        _W1 = _W1 - learning_rate * (dW1 / m) + ( (reg_param / m) * _W1)\n",
    "        _W2 = _W2 - learning_rate * (dW2 / m) + ( (reg_param / m) * _W2)\n",
    "\n",
    "        _B1 = _B1 - learning_rate * (dB1 / m)\n",
    "        _B2 = _B2 - learning_rate * (dB2 / m)\n",
    "        cost[i] = (c / m) + ( \n",
    "            (reg_param / (2 * m)) * \n",
    "            (\n",
    "                np.sum(np.power(_W1, 2)) + \n",
    "                np.sum(np.power(_W2, 2))\n",
    "            )\n",
    "        )\n",
    "    return (_W1, _W2, _B1, _B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running\n",
    "Now, let's try out the NN. Here, I have called the train() function. You can make any changes you like and then run all the kernels again. I have also plotted the cost function to visual how the NN performed.\n",
    "\n",
    "The console printing might be off.\n",
    "\n",
    "The weights and biases are then shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5000 and 4"
     ]
    }
   ],
   "source": [
    "W1, W2, B1, B2 = train(W1, W2, B1, B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.32260643, -0.42332921],\n",
       "       [-1.4336158 , -1.67239068]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25299514, -2.21317287]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37348207],\n",
       "       [-0.22080277]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24523225]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "Now, let's plot a simple plot showing the cost function with respect to the number of iterations of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6e74710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assigning the axes to the different elements.\n",
    "plt.plot(range(max_iter), cost)\n",
    "\n",
    "# Labelling the x axis as the iterations axis.\n",
    "plt.xlabel(\"Iterations\")\n",
    "\n",
    "# Labelling the y axis as the cost axis.\n",
    "plt.ylabel(\"Cost\")\n",
    "\n",
    "# Showing the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "With the initial parameters, the cost function doesn't look that good. It is decreasing which is a good sign but it isn't flattening out. I have tried, multiple different values but this some seems like the best fit.\n",
    "\n",
    "Try out your own values, run the notebook again and see what you get."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
